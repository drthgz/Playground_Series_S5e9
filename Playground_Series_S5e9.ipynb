{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91720,"databundleVersionId":13345277,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":10.17418,"end_time":"2025-09-08T04:52:09.151814","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-09-08T04:51:58.977634","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/syedfarazhussaini/playground-series-s5e9?scriptVersionId=260768283\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-09-09T03:30:17.250327Z","iopub.execute_input":"2025-09-09T03:30:17.25061Z","iopub.status.idle":"2025-09-09T03:30:17.257324Z","shell.execute_reply.started":"2025-09-09T03:30:17.250592Z","shell.execute_reply":"2025-09-09T03:30:17.256598Z"},"papermill":{"duration":2.354273,"end_time":"2025-09-08T04:52:08.526426","exception":false,"start_time":"2025-09-08T04:52:06.172153","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step-by-Step Guide: Predicting the Beats-per-Minute of Songs\nWelcome to the Kaggle Playground Series S5E9! This notebook will guide you through the process of building a model to predict the beats-per-minute (BPM) of songs.\n\n## Steps\n1. **Understand the Problem**  \n   - Review the competition goal and data format.\n2. **Import Libraries & Load Data**  \n   - Import necessary Python libraries.\n   - Load the training and test datasets.\n3. **Explore the Data (EDA)**  \n   - Inspect the data structure, check for missing values, and visualize distributions.\n4. **Preprocess the Data**  \n   - Handle missing values, encode categorical variables, and scale features if needed.\n5. **Build a Baseline Model**  \n   - Train a simple regression model (e.g., Linear Regression, Random Forest, or XGBoost).\n6. **Evaluate the Model**  \n   - Use cross-validation or a validation split to assess performance.\n7. **Feature Engineering & Model Improvement**  \n   - Try new features, different models, or hyperparameter tuning to improve results.\n8. **Make Predictions on Test Data**  \n   - Generate predictions for the test set.\n9. **Prepare Submission**  \n   - Format predictions according to `sample_submission.csv` and save for submission.\n10. **Submit to Kaggle**  \n   - Upload your submission and review your score.\n\nLet's get started!","metadata":{}},{"cell_type":"markdown","source":"## 1. Import Libraries & Load Data\nLet's import the necessary libraries and load the training, test, and sample submission datasets.","metadata":{}},{"cell_type":"code","source":"# Import libraries\nimport numpy as np\nimport pandas as pd\n\n# Load datasets\nfilePath = \"/kaggle/input/playground-series-s5e9\"\ntrain = pd.read_csv(f'{filePath}/train.csv')\ntest = pd.read_csv(f'{filePath}/test.csv')\nsample_submission = pd.read_csv(f'{filePath}/sample_submission.csv')\n\n# Show the shape of the datasets\nprint('Train shape:', train.shape)\nprint('Test shape:', test.shape)\nprint('Sample submission shape:', sample_submission.shape)\n\n# Display the first few rows of the training data\ntrain.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T03:30:17.258778Z","iopub.execute_input":"2025-09-09T03:30:17.259019Z","iopub.status.idle":"2025-09-09T03:30:18.985606Z","shell.execute_reply.started":"2025-09-09T03:30:17.259001Z","shell.execute_reply":"2025-09-09T03:30:18.984895Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Explore the Data (EDA)\nLet's start exploring the data. We'll begin by checking the structure, types, and summary statistics of the training set.","metadata":{}},{"cell_type":"markdown","source":"### 2.1. Data Structure and Types\nLet's check the columns, data types, and missing values in the training data.","metadata":{}},{"cell_type":"code","source":"# Show columns and data types\nprint(train.dtypes)\n\n# Check for missing values\nprint('\\nMissing values per column:')\nprint(train.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T03:30:18.986431Z","iopub.execute_input":"2025-09-09T03:30:18.986793Z","iopub.status.idle":"2025-09-09T03:30:19.013347Z","shell.execute_reply.started":"2025-09-09T03:30:18.986773Z","shell.execute_reply":"2025-09-09T03:30:19.012421Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2.2. Summary Statistics\nNow, let's look at summary statistics for the numeric features in the training data.","metadata":{}},{"cell_type":"code","source":"# Summary statistics for numeric columns\ntrain.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T03:30:19.015059Z","iopub.execute_input":"2025-09-09T03:30:19.015306Z","iopub.status.idle":"2025-09-09T03:30:19.306173Z","shell.execute_reply.started":"2025-09-09T03:30:19.015288Z","shell.execute_reply":"2025-09-09T03:30:19.305248Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2.3. Target Variable Distribution\nLet's visualize the distribution of the target variable (BPM) to understand its range and shape.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Plot the distribution of the target variable (assuming 'BeatsPerMinute' is the target column)\nplt.figure(figsize=(8, 4))\nsns.histplot(train['BeatsPerMinute'], kde=True, bins=30)\nplt.title('Distribution of BPM (Target Variable)')\nplt.xlabel('BPM')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T03:30:19.307052Z","iopub.execute_input":"2025-09-09T03:30:19.307359Z","iopub.status.idle":"2025-09-09T03:30:21.923967Z","shell.execute_reply.started":"2025-09-09T03:30:19.307339Z","shell.execute_reply":"2025-09-09T03:30:21.923024Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2.4. Feature Distributions and Relationships\nLet's visualize the distributions of some features and their relationships with the target variable (BPM).","metadata":{}},{"cell_type":"code","source":"# Plot distributions for a few numeric features and their relationship with BPM\nnumeric_features = train.select_dtypes(include=[np.number]).columns.tolist()\nnumeric_features = [f for f in numeric_features if f != 'BeatsPerMinute']  # Exclude target\nsample_features = numeric_features[:3]  # Plot first 3 features as example\n\nfig, axes = plt.subplots(len(sample_features), 2, figsize=(12, 4 * len(sample_features)))\nfor i, feature in enumerate(sample_features):\n    # Distribution\n    sns.histplot(train[feature], kde=True, ax=axes[i, 0])\n    axes[i, 0].set_title(f'Distribution of {feature}')\n    # Relationship with BeatsPerMinute\n    sns.scatterplot(x=train[feature], y=train['BeatsPerMinute'], ax=axes[i, 1], alpha=0.3)\n    axes[i, 1].set_title(f'{feature} vs BeatsPerMinute')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T03:30:21.924912Z","iopub.execute_input":"2025-09-09T03:30:21.925237Z","iopub.status.idle":"2025-09-09T03:30:34.177607Z","shell.execute_reply.started":"2025-09-09T03:30:21.925211Z","shell.execute_reply":"2025-09-09T03:30:34.176468Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Preprocess the Data\nLet's prepare the data for modeling. We'll start by handling missing values, then encode categorical variables, and finally scale features if needed.","metadata":{}},{"cell_type":"markdown","source":"### 3.1. Handle Missing Values\nFirst, let's check again for missing values and decide how to handle them. We'll fill or drop missing values as appropriate.","metadata":{}},{"cell_type":"code","source":"# Handle missing values (example: fill numeric with median, categorical with mode)\nfor col in train.columns:\n    if train[col].isnull().sum() > 0:\n        if train[col].dtype == 'object':\n            mode = train[col].mode()[0]\n            train[col].fillna(mode, inplace=True)\n            test[col].fillna(mode, inplace=True)\n        else:\n            median = train[col].median()\n            train[col].fillna(median, inplace=True)\n            test[col].fillna(median, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T03:30:34.179172Z","iopub.execute_input":"2025-09-09T03:30:34.179561Z","iopub.status.idle":"2025-09-09T03:30:34.21173Z","shell.execute_reply.started":"2025-09-09T03:30:34.179526Z","shell.execute_reply":"2025-09-09T03:30:34.210706Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3.2. Encode Categorical Variables\nNext, we'll convert any categorical features into numeric format using one-hot encoding.","metadata":{}},{"cell_type":"code","source":"# One-hot encode categorical variables\ncategorical_cols = train.select_dtypes(include=['object']).columns.tolist()\ntrain_encoded = pd.get_dummies(train, columns=categorical_cols)\ntest_encoded = pd.get_dummies(test, columns=categorical_cols)\n\n# Align train and test dataframes to have the same columns\ntrain_encoded, test_encoded = train_encoded.align(test_encoded, join='left', axis=1, fill_value=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T03:30:34.212834Z","iopub.execute_input":"2025-09-09T03:30:34.213398Z","iopub.status.idle":"2025-09-09T03:30:34.312105Z","shell.execute_reply.started":"2025-09-09T03:30:34.213372Z","shell.execute_reply":"2025-09-09T03:30:34.311143Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3.3. Feature Scaling (Optional)\nFor some models, scaling features can improve performance. We'll use StandardScaler as an example.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Identify feature columns (exclude target and any ID columns)\ntarget_col = 'BeatsPerMinute'  # Update if your target column is named differently\nfeature_cols = [col for col in train_encoded.columns if col != target_col]\n\nscaler = StandardScaler()\ntrain_encoded[feature_cols] = scaler.fit_transform(train_encoded[feature_cols])\ntest_encoded[feature_cols] = scaler.transform(test_encoded[feature_cols])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T03:30:34.31433Z","iopub.execute_input":"2025-09-09T03:30:34.314601Z","iopub.status.idle":"2025-09-09T03:30:34.631344Z","shell.execute_reply.started":"2025-09-09T03:30:34.314579Z","shell.execute_reply":"2025-09-09T03:30:34.630442Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Build a Baseline Model\nLet's train a simple regression model as a baseline. We'll use a Random Forest Regressor and evaluate its performance using cross-validation.","metadata":{}},{"cell_type":"markdown","source":"**Update:** The Random Forest model was taking too long to run. We'll now use fewer trees (`n_estimators=10`) and fewer cross-validation folds (`cv=3`) for much faster testing.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_score\n\n# Split features and target\nX = train_encoded[feature_cols]\ny = train_encoded[target_col]\n\n# Faster Random Forest for testing\nrf = RandomForestRegressor(n_estimators=10, random_state=42)\n\n# Faster cross-validation\nscores = cross_val_score(rf, X, y, cv=3, scoring='neg_root_mean_squared_error')\nprint('Cross-validated RMSE (fast version):', -scores.mean())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T03:30:34.632293Z","iopub.execute_input":"2025-09-09T03:30:34.63255Z","iopub.status.idle":"2025-09-09T03:35:47.779614Z","shell.execute_reply.started":"2025-09-09T03:30:34.632531Z","shell.execute_reply":"2025-09-09T03:35:47.778559Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fit the model on the full training data\nrf.fit(X, y)\n\n# Predict on the test set\ntest_preds = rf.predict(test_encoded[feature_cols])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T03:35:47.780865Z","iopub.execute_input":"2025-09-09T03:35:47.781213Z","iopub.status.idle":"2025-09-09T03:38:38.57586Z","shell.execute_reply.started":"2025-09-09T03:35:47.781183Z","shell.execute_reply":"2025-09-09T03:38:38.574922Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare the submission DataFrame (make sure the column name matches sample_submission)\nsubmission = sample_submission.copy()\nsubmission['BeatsPerMinute'] = test_preds  # Update column name if needed\n\n# Save to CSV for Kaggle submission\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Submission file 'submission.csv' created!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T03:38:38.576776Z","iopub.execute_input":"2025-09-09T03:38:38.577003Z","iopub.status.idle":"2025-09-09T03:38:38.96987Z","shell.execute_reply.started":"2025-09-09T03:38:38.576986Z","shell.execute_reply":"2025-09-09T03:38:38.968959Z"}},"outputs":[],"execution_count":null}]}